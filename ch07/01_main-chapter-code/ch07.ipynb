{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12e91914-5f51-43fa-b65b-625e73b4d17b",
   "metadata": {
    "id": "12e91914-5f51-43fa-b65b-625e73b4d17b"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp?1\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2520ec3-722f-4f44-bdd1-885b13e7afbf",
   "metadata": {
    "id": "c2520ec3-722f-4f44-bdd1-885b13e7afbf"
   },
   "source": [
    "# 第7章：微调以遵循指令"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e19327b-6c02-4881-ad02-9b6d3ec0b1b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4e19327b-6c02-4881-ad02-9b6d3ec0b1b4",
    "outputId": "bcdfe2cb-d084-4920-d703-503131aabec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.26.3\n",
      "matplotlib version: 3.9.4\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.7.1+cu118\n",
      "tqdm version: 4.67.1\n",
      "tensorflow version: 2.19.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"numpy\",       # PyTorch & TensorFlow dependency\n",
    "    \"matplotlib\",  # Plotting library\n",
    "    \"tiktoken\",    # Tokenizer\n",
    "    \"torch\",       # Deep learning library\n",
    "    \"tqdm\",        # Progress bar\n",
    "    \"tensorflow\",  # For OpenAI's pretrained weights\n",
    "]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264fca98-2f9a-4193-b435-2abfa3b4142f",
   "metadata": {
    "id": "264fca98-2f9a-4193-b435-2abfa3b4142f"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/overview.webp?1\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbc68e9-75b3-41f1-ac2c-e071c3cd0813",
   "metadata": {
    "id": "8bbc68e9-75b3-41f1-ac2c-e071c3cd0813"
   },
   "source": [
    "## 7.1 指令微调介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dba24a-6805-496c-9a7f-c75e2d3527ab",
   "metadata": {
    "id": "53dba24a-6805-496c-9a7f-c75e2d3527ab"
   },
   "source": [
    "- 在第5章中，我们看到预训练一个大型语言模型涉及一个训练过程，其中模型学习一次生成一个词。\n",
    "- 因此，预训练的大型语言模型擅长文本补全，但不擅长遵循指令。\n",
    "- 在本章中，我们将教大型语言模型更好地遵循指令。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dc0535-0904-44ed-beaf-9b678292ef35",
   "metadata": {
    "id": "18dc0535-0904-44ed-beaf-9b678292ef35"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/instruction-following.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4698b23-12e0-4bd7-a140-ccb3dd71d4e8",
   "metadata": {
    "id": "b4698b23-12e0-4bd7-a140-ccb3dd71d4e8"
   },
   "source": [
    "- 本章涵盖的主题如下图所示\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-1.webp?1\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5384f0cf-ef3c-4436-a5fa-59bd25649f86",
   "metadata": {
    "id": "5384f0cf-ef3c-4436-a5fa-59bd25649f86"
   },
   "source": [
    "## 7.2 为监督指令微调准备数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b34ff8-619f-4e89-bd03-ce513269760d",
   "metadata": {
    "id": "f8b34ff8-619f-4e89-bd03-ce513269760d"
   },
   "source": [
    "- 我们将使用我为本章准备的指令数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0G3axLw6kY1N",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0G3axLw6kY1N",
    "outputId": "07e1e4f9-026c-48c1-8a06-f2bfb1fb354e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "\n",
    "    # The book originally contained this unnecessary \"else\" clause:\n",
    "    #else:\n",
    "    #    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    #        text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7af8176-4255-4e92-8c7d-998771733eb8",
   "metadata": {
    "id": "d7af8176-4255-4e92-8c7d-998771733eb8"
   },
   "source": [
    "- 我们从上面的JSON文件中加载的 `data` 列表中的每个项目都是以下形式的字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "-LiuBMsHkzQV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-LiuBMsHkzQV",
    "outputId": "a4ee5c2d-db53-4a80-e5ee-0bbcf6fe0450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a32b34-485a-4816-a77a-da14f9fe6e46",
   "metadata": {
    "id": "c5a32b34-485a-4816-a77a-da14f9fe6e46"
   },
   "source": [
    "- 请注意， `'input'` 字段可以为空："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "uFInFxDDk2Je",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uFInFxDDk2Je",
    "outputId": "b4f84027-bb9e-4e51-b79e-1329c8bff093"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Another example entry:\\n\", data[999])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f034799a-6575-45fd-98c9-9d1012d0fd58",
   "metadata": {
    "id": "f034799a-6575-45fd-98c9-9d1012d0fd58"
   },
   "source": [
    "- 指令微调（instruction finetuning）通常被称为“监督指令微调”（supervised instruction finetuning），因为它涉及在一个输入-输出对明确提供的数据集上训练模型[4]。\n",
    "- 对于输入到大型语言模型（LLM）的条目，有不同的格式化方式；下图展示了两种示例格式，分别用于训练Alpaca (https://crfm.stanford.edu/2023/03/13/alpaca.html) 和 Phi-3 (https://arxiv.org/abs/2404.14219) LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffa4f70-44d4-4be4-89a9-2159f4885b10",
   "metadata": {
    "id": "dffa4f70-44d4-4be4-89a9-2159f4885b10"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/prompt-style.webp?1\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd79a74e-befb-491c-be49-f777a6a5b6a6",
   "metadata": {
    "id": "dd79a74e-befb-491c-be49-f777a6a5b6a6"
   },
   "source": [
    "- 在本章中，我们使用Alpaca风格的提示格式化，这是指令微调的原始提示模板。\n",
    "- 下面，我们格式化将要传递给LLM的输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "Jhk37nnJnkBh",
   "metadata": {
    "id": "Jhk37nnJnkBh"
   },
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011e78b4-e89a-4653-a2ee-7b2739ca04d6",
   "metadata": {
    "id": "011e78b4-e89a-4653-a2ee-7b2739ca04d6"
   },
   "source": [
    "- 包含输入字段的格式化响应如下所示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "F9UQRfjzo4Js",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F9UQRfjzo4Js",
    "outputId": "7b615d35-2a5f-474d-9292-a69bc3850e16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc93ddf-431c-49c0-96f2-fb3a79c4d94c",
   "metadata": {
    "id": "4dc93ddf-431c-49c0-96f2-fb3a79c4d94c"
   },
   "source": [
    "- 下面是一个不包含输入字段的格式化响应"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3891fa9-f738-41cd-946c-80ef9a99c346",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3891fa9-f738-41cd-946c-80ef9a99c346",
    "outputId": "2142c5a4-b594-49c5-affe-2d963a7bd46b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa8afd5-2a21-49a5-90c3-6a03865a4771",
   "metadata": {
    "id": "4aa8afd5-2a21-49a5-90c3-6a03865a4771"
   },
   "source": [
    "- 最后，在下一节中我们准备PyTorch数据加载器之前，我们将数据集分为训练集、验证集和测试集 对于数据集的分割，通常的做法是将数据集按照某种比例（例如80%训练集、10%验证集、10%测试集）进行划分。这样可以确保模型在训练时有足够的数据学习，并且在验证和测试时有独立的数据集来评估其性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aFZVopbIlNfx",
   "metadata": {
    "id": "aFZVopbIlNfx"
   },
   "outputs": [],
   "source": [
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "-zf6oht6bIUQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-zf6oht6bIUQ",
    "outputId": "657ec5c6-4caa-4d1a-ba2e-23acd755ab07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaaf606-f913-4445-8301-632ae10d387d",
   "metadata": {
    "id": "fcaaf606-f913-4445-8301-632ae10d387d"
   },
   "source": [
    "## 7.3 将数据组织成训练批次"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233f63bd-9755-4d07-8884-5e2e5345cf27",
   "metadata": {
    "id": "233f63bd-9755-4d07-8884-5e2e5345cf27"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-2.webp?1\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c149fc1a-7757-4ec8-80cb-e2a3fb007a2c",
   "metadata": {
    "id": "c149fc1a-7757-4ec8-80cb-e2a3fb007a2c"
   },
   "source": [
    "- 我们将数据集分批处理分为几个步骤，如下图所示\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/detailed-batching.webp?1\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9af423f-aad9-4b3c-bea5-153021c04862",
   "metadata": {
    "id": "b9af423f-aad9-4b3c-bea5-153021c04862"
   },
   "source": [
    "- 首先，我们实现一个 `InstructionDataset` 类，该类会对数据集中的所有输入进行预分词，类似于第6章中的 `SpamDataset` 类。\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/pretokenizing.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adc29dc4-f1c7-4c71-937b-95119d6239bb",
   "metadata": {
    "id": "adc29dc4-f1c7-4c71-937b-95119d6239bb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384f0e69-4b22-41c0-a25d-f077527eddd1",
   "metadata": {
    "id": "384f0e69-4b22-41c0-a25d-f077527eddd1"
   },
   "source": [
    "- 类似于第6章，我们希望在一个批次中收集多个训练样本以加速训练；这需要将所有输入填充到类似的长度。\n",
    "- 与前一章类似，我们使用 `<|endoftext|>` 标记作为填充标记。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff24fe1a-5746-461c-ad3d-b6d84a1a7c96",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff24fe1a-5746-461c-ad3d-b6d84a1a7c96",
    "outputId": "ac44227b-9ec2-4131-9df8-89caa6e879ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5bd7bc-f347-4cf8-a0c2-94cb8799e427",
   "metadata": {
    "id": "9e5bd7bc-f347-4cf8-a0c2-94cb8799e427"
   },
   "source": [
    "- 在第6章中，我们将数据集中的所有示例填充到相同的长度。\n",
    "  - 这里，我们采取更复杂的方法，开发一个自定义的“collate”函数，可以传递给数据加载器。\n",
    "  - 这个自定义的collate函数会将每个批次中的训练示例填充到相同的长度（但不同的批次可以有不同的长度）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c4d943-4aa8-4a44-874e-05bc6831fbd3",
   "metadata": {
    "id": "65c4d943-4aa8-4a44-874e-05bc6831fbd3"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/padding.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb4c77dd-c956-4a1b-897b-b466909f18ca",
   "metadata": {
    "id": "eb4c77dd-c956-4a1b-897b-b466909f18ca"
   },
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    # and increase the max length by +1, which will add one extra\n",
    "    # padding token below\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst = []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to batch_max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # Via padded[:-1], we remove the extra padded token\n",
    "        # that has been added via the +1 setting in batch_max_length\n",
    "        # (the extra padding token will be relevant in later codes)\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fb02373-59b3-4f3a-b1d1-8181a2432645",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8fb02373-59b3-4f3a-b1d1-8181a2432645",
    "outputId": "93d987b9-e3ca-4857-9b28-b67d515a94d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46832ab-39b7-45f8-b330-ac9adfa10d1b",
   "metadata": {
    "id": "c46832ab-39b7-45f8-b330-ac9adfa10d1b"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/batching-step-4.webp?1\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17769a19-b961-4213-92ef-34f441b2d1d6",
   "metadata": {
    "id": "17769a19-b961-4213-92ef-34f441b2d1d6"
   },
   "source": [
    "- 在上面，我们只返回了传递给LLM的输入；然而，对于LLM训练，我们还需要目标值。\n",
    "- 类似于预训练一个LLM，目标值是将输入向右移动1个位置，这样LLM可以学习预测下一个标记。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0386b6fe-3455-4e70-becd-a5a4681ba2ef",
   "metadata": {
    "id": "0386b6fe-3455-4e70-becd-a5a4681ba2ef"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/inputs-targets.webp?1\" width=400px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74af192e-757c-4c0a-bdf9-b7eb25bf6ebc",
   "metadata": {
    "id": "74af192e-757c-4c0a-bdf9-b7eb25bf6ebc"
   },
   "outputs": [],
   "source": [
    "def custom_collate_draft_2(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6eb2bce3-28a7-4f39-9d4b-5e972d69066c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6eb2bce3-28a7-4f39-9d4b-5e972d69066c",
    "outputId": "3d104439-c328-431b-ef7c-2639d86c2135"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf85703-a0e0-42aa-8f29-cbc28dbf4e15",
   "metadata": {
    "id": "3bf85703-a0e0-42aa-8f29-cbc28dbf4e15"
   },
   "source": [
    "- 接下来，我们引入一个 `ignore_index` 值，将所有填充标记的ID替换为一个新值；这个 `ignore_index` 的目的是在损失函数中忽略填充值（稍后会详细介绍）。\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/batching-step-5.webp?1\" width=500px>\n",
    "\n",
    "- 具体来说，这意味着我们将所有对应于 `50256` 的标记ID替换为 `-100`，如下图所示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4bed33-956e-4b3f-a09c-586d8203109a",
   "metadata": {
    "id": "bd4bed33-956e-4b3f-a09c-586d8203109a"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/ignore-index.webp?1\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5346513e-c3f4-44fe-af22-4ebd36497728",
   "metadata": {
    "id": "5346513e-c3f4-44fe-af22-4ebd36497728"
   },
   "source": [
    "- （此外，我们还引入了`allowed_max_length` ，以便在需要时限制样本的长度；这对于你打算使用自己数据集且这些数据集的长度超过GPT-2模型支持的1024个标记的上下文大小的情况会很有用。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41ec6e2d-9eb2-4124-913e-d2af39be4cf2",
   "metadata": {
    "id": "41ec6e2d-9eb2-4124-913e-d2af39be4cf2"
   },
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs and targets\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "\n",
    "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        # New: Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs and targets to tensors and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdf5eec4-9ebe-4be0-9fca-9a47bee88fdc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cdf5eec4-9ebe-4be0-9fca-9a47bee88fdc",
    "outputId": "e8f709b9-f4c5-428a-a6ac-2a4c1b9358ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26727c90-0d42-43b3-af21-0a66ad4fbbc7",
   "metadata": {
    "id": "26727c90-0d42-43b3-af21-0a66ad4fbbc7"
   },
   "source": [
    "- 让我们看看将某个值替换为-100的作用是什么\n",
    "- 为了说明目的，我们假设有一个小的分类任务，包含两个类别标签0和1，类似于第6章的内容\n",
    "- 如果我们有以下logits值（模型最后一层的输出），我们将计算出相应的损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "W2jvh-OP9MFV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W2jvh-OP9MFV",
    "outputId": "ccb3a703-59a7-4258-8841-57959a016e31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],  # 1st training example\n",
    "     [-0.5, 1.5]]  # 2nd training example\n",
    ")\n",
    "targets_1 = torch.tensor([0, 1])\n",
    "\n",
    "\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edd3244-8886-4505-92e9-367d28529e1e",
   "metadata": {
    "id": "5edd3244-8886-4505-92e9-367d28529e1e"
   },
   "source": [
    "- 现在，添加一个训练样本，正如预期的那样，将会对损失产生影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "nvVMuil89v9N",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nvVMuil89v9N",
    "outputId": "6d4683d4-5bfc-4a8c-de2a-95ecb2e716b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]  # New 3rd training example\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dca331-40e0-468b-b690-189fe156ba8f",
   "metadata": {
    "id": "54dca331-40e0-468b-b690-189fe156ba8f"
   },
   "source": [
    "- 让我们看看如果将某个样本的类别标签替换为-100会发生什么情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "RTyB1vah9p56",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RTyB1vah9p56",
    "outputId": "da05302e-3fe0-439e-d1ed-82066bceb122"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef09d21-b652-4760-abea-4f76920e6a25",
   "metadata": {
    "id": "cef09d21-b652-4760-abea-4f76920e6a25"
   },
   "source": [
    "- 如我们所见，这3个训练样本的最终损失与我们从2个训练样本计算出的损失相同，这意味着交叉熵损失函数忽略了标签为-100的训练样本。\n",
    "- 默认情况下，PyTorch的 `cross_entropy(..., ignore_index=-100)` 设置会忽略标签为-100的样本。\n",
    "- 使用这个-100的 `ignore_index`，我们可以忽略批次中额外的结束-of-text（填充）标记，这些标记是我们用来将训练样本填充到相同长度的。\n",
    "- 然而，我们不希望忽略结束-of-text（填充）标记（50256）的第一个出现，因为它可以帮助大型语言模型（LLM）判断响应何时完成。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4e9c5f-7c49-4321-9f1b-a50468a84524",
   "metadata": {
    "id": "6a4e9c5f-7c49-4321-9f1b-a50468a84524"
   },
   "source": [
    "- 实际应用中，通常还会屏蔽掉与指令对应的target token IDs，如下面的图所示（这是在完成本章后推荐的读者练习）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab8f0ed-80e8-4fd9-bf84-e5d0e0bc0a39",
   "metadata": {
    "id": "fab8f0ed-80e8-4fd9-bf84-e5d0e0bc0a39"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/mask-instructions.webp?1\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccaf048-ec95-498c-9155-d5b3ccba6c96",
   "metadata": {
    "id": "bccaf048-ec95-498c-9155-d5b3ccba6c96"
   },
   "source": [
    "## 7.4 为指令数据集创建数据加载器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b8e656-3af3-4db6-8dde-d8c216a12f50",
   "metadata": {
    "id": "e6b8e656-3af3-4db6-8dde-d8c216a12f50"
   },
   "source": [
    "- 在本节中，我们使用 InstructionDataset 类和 custom_collate_fn 函数来实例化训练、验证和测试数据加载器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fffe390-b226-4d5c-983f-9f4da773cb82",
   "metadata": {
    "id": "9fffe390-b226-4d5c-983f-9f4da773cb82"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-3.webp?1\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932677e9-9317-42e8-b461-7b0269518f97",
   "metadata": {
    "id": "932677e9-9317-42e8-b461-7b0269518f97"
   },
   "source": [
    "- 上一个 `custom_collate_fn` 函数的另一个附加细节是我们现在直接将数据移动到目标设备（例如GPU），而不是在主训练循环中进行，这可以提高效率，因为当我们使用 `custom_collate_fn` 作为数据加载器的一部分时，它可以作为后台进程进行。\n",
    "- 使用 Python 标准库  `functools` 中的 `partial` 函数，我们创建了一个新函数，并预先填充了原始函数中的 `device` 参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "etpqqWh8phKc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "etpqqWh8phKc",
    "outputId": "b4391c33-1a89-455b-faaa-5f874b6eb409"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is much faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# However, the resulting loss values may be slightly different.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e47fb30-c2c6-4e6d-a64c-76cc65be4a2c",
   "metadata": {
    "id": "4e47fb30-c2c6-4e6d-a64c-76cc65be4a2c"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff42c29-8b81-45e5-ae8d-b97cd1cf447a",
   "metadata": {
    "id": "8ff42c29-8b81-45e5-ae8d-b97cd1cf447a"
   },
   "source": [
    "- 接下来，我们实例化数据加载器，类似于之前的章节，不同之处是我们现在为批处理过程提供了自己的 collate 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "BtWkgir6Hlpe",
   "metadata": {
    "id": "BtWkgir6Hlpe"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d097dc8-ad34-4f05-b435-e4147965f532",
   "metadata": {
    "id": "1d097dc8-ad34-4f05-b435-e4147965f532"
   },
   "outputs": [],
   "source": [
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f67c147-b1a2-4a95-9807-e2d0de0324c0",
   "metadata": {
    "id": "3f67c147-b1a2-4a95-9807-e2d0de0324c0"
   },
   "source": [
    "- 让我们看看生成的输入和目标批次的维度是什么样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "GGs1AI3vHpnX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GGs1AI3vHpnX",
    "outputId": "f6a74c8b-1af3-4bc1-b48c-eda64b0200d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8e8dd7-d46a-4cc3-8a7e-c1d31e1b4657",
   "metadata": {
    "id": "0c8e8dd7-d46a-4cc3-8a7e-c1d31e1b4657"
   },
   "source": [
    "- 根据上面的输出，我们可以看到所有批次的批量大小都是 8，但长度不同，这与预期一致。\n",
    "- 我们还可以通过打印 `inputs` 批次中的第一个训练示例的内容来进一步确认输入中是否包含对应于 token ID 50256 的 `<|endoftext|>` 填充标记。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21b8fd02-014f-4481-9b71-5bfee8f9dfcd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21b8fd02-014f-4481-9b71-5bfee8f9dfcd",
    "outputId": "1b8ad342-2b5b-4f12-ad1a-3cb2a6c712ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "          985,   576,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "         5156,   318,   845, 13779,    13,   198,   198, 21017, 18261,    25,\n",
      "          198,   464,  5156,   318,   355, 13779,   355,   257,  4936,    13,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1f3647-8971-4006-89e0-6a2a1ec1d360",
   "metadata": {
    "id": "5f1f3647-8971-4006-89e0-6a2a1ec1d360"
   },
   "source": [
    "- 同样地，我们通过可视化检查来确认目标中是否包含 -100 的占位符标记。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51649ab4-1a7e-4a9e-92c5-950a24fde211",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51649ab4-1a7e-4a9e-92c5-950a24fde211",
    "outputId": "5e8c23f8-6a05-4c13-9f92-373b75b57ea6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "        46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,   985,\n",
      "          576,    13,   198,   198, 21017, 23412,    25,   198,   464,  5156,\n",
      "          318,   845, 13779,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "          464,  5156,   318,   355, 13779,   355,   257,  4936,    13, 50256,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(targets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6aad445-8f19-4238-b9bf-db80767fb91a",
   "metadata": {
    "id": "d6aad445-8f19-4238-b9bf-db80767fb91a"
   },
   "source": [
    "## 7.5 加载预训练的 LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5c07d1-4fc9-4846-94cf-b11a085a667b",
   "metadata": {
    "id": "5a5c07d1-4fc9-4846-94cf-b11a085a667b"
   },
   "source": [
    "- 在本节中，我们使用与第 5 章第 5.5 节和第 6 章第 6.4 节中相同的代码加载一个预训练的 GPT 模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1b438f-88af-413f-96a9-f059c6c55fc4",
   "metadata": {
    "id": "8d1b438f-88af-413f-96a9-f059c6c55fc4"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-4.webp?1\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c68eda7-e02e-4caa-846b-ca6dbd396ca2",
   "metadata": {
    "id": "8c68eda7-e02e-4caa-846b-ca6dbd396ca2"
   },
   "source": [
    "- 然而，我们加载的是包含 3.55 亿参数的中型版本模型，而不是包含 1.24 亿参数的最小版本模型，因为 1.24 亿参数的模型对于通过指令微调获得定性合理的结果来说太小了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d249d67-5eba-414e-9bd2-972ebf01329d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0d249d67-5eba-414e-9bd2-972ebf01329d",
    "outputId": "386ebd49-51d7-4a62-c590-91cdccce5fb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\355M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\355M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\355M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "# If the `previous_chapters.py` file is not available locally,\n",
    "# you can import it from the `llms-from-scratch` PyPI package.\n",
    "# For details, see: https://github.com/rasbt/LLMs-from-scratch/tree/main/pkg\n",
    "# E.g.,\n",
    "# from llms_from_scratch.ch04 import GPTModel\n",
    "# from llms_from_scratch.ch05 import download_and_load_gpt2, load_weights_into_gpt\n",
    "\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf3afed-bc8e-4d3a-ad9d-eb6f57bb7af5",
   "metadata": {
    "id": "dbf3afed-bc8e-4d3a-ad9d-eb6f57bb7af5"
   },
   "source": [
    "- 在下一节开始微调模型之前，让我们看看它在验证任务中的表现如何。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7bd32b7c-5b44-4d25-a09f-46836802ca74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7bd32b7c-5b44-4d25-a09f-46836802ca74",
    "outputId": "c1276a91-e7da-495b-be0f-70a96872dbe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e3e68e0-2627-4c65-b4e7-1e0667e4f6fa",
   "metadata": {
    "id": "2e3e68e0-2627-4c65-b4e7-1e0667e4f6fa"
   },
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    generate,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "# Alternatively:\n",
    "# from llms_from_scratch.ch05 import (\n",
    "#    generate,\n",
    "#    text_to_token_ids,\n",
    "#    token_ids_to_text\n",
    "# )\n",
    "\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e2fda5-f796-4954-8f72-1dd1123e3344",
   "metadata": {
    "id": "36e2fda5-f796-4954-8f72-1dd1123e3344"
   },
   "source": [
    "- 请注意，我们在前几章中使用的 `generate` 函数返回的是结合了输入和输出文本的文本，这在上一节中便于生成可读的文本。\n",
    "- 为了隔离响应，我们可以从 `generated_text` 的起始位置减去指令的长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba4a55bf-a245-48d8-beda-2838a58fb5ba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ba4a55bf-a245-48d8-beda-2838a58fb5ba",
    "outputId": "3e231f03-c5dc-4397-8778-4995731176a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "response_text = (\n",
    "    generated_text[len(input_text):]\n",
    "    .replace(\"### Response:\", \"\")\n",
    "    .strip()\n",
    ")\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44080b2-a4c5-4520-a797-549519f66a3e",
   "metadata": {
    "id": "d44080b2-a4c5-4520-a797-549519f66a3e"
   },
   "source": [
    "- 如我们所见，模型目前还无法遵循指令；它创建了一个“Response”部分，但只是简单地重复了原始输入句子以及指令本身。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d27b9d-a942-4cf5-b797-848c5f01e723",
   "metadata": {
    "id": "70d27b9d-a942-4cf5-b797-848c5f01e723"
   },
   "source": [
    "## 7.6 在指令数据上微调 LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314b2a39-88b4-44d8-8c85-1c5b0cd6cc4a",
   "metadata": {
    "id": "314b2a39-88b4-44d8-8c85-1c5b0cd6cc4a"
   },
   "source": [
    "- 在本节中，我们将对模型进行微调。\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-5.webp?1\" width=500px>\n",
    "\n",
    "- 注意，我们可以重用之前章节中使用的所有损失计算和训练函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65444865-df87-4d98-9faf-875e1c4be860",
   "metadata": {
    "id": "65444865-df87-4d98-9faf-875e1c4be860"
   },
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    calc_loss_loader,\n",
    "    train_model_simple\n",
    ")\n",
    "# Alternatively:\n",
    "# from llms_from_scratch.ch05 import (\n",
    "#    calc_loss_loader,\n",
    "#    train_model_simple,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00083059-aa41-4d37-8a17-1c72d1b1ca00",
   "metadata": {
    "id": "00083059-aa41-4d37-8a17-1c72d1b1ca00"
   },
   "source": [
    "- 在开始训练之前，我们先计算初始的训练集和验证集的损失（与之前的章节一样，目标是最小化损失）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d99fc6f8-63b2-43da-adbb-a7b6b92c8dd5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d99fc6f8-63b2-43da-adbb-a7b6b92c8dd5",
    "outputId": "a3f5e1b0-093a-4c51-e7fc-c9cac48c2ea2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.8259096145629883\n",
      "Validation loss: 3.7619340419769287\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a6da8f-15b3-42b0-a136-619b7a35c3e9",
   "metadata": {
    "id": "12a6da8f-15b3-42b0-a136-619b7a35c3e9"
   },
   "source": [
    "- 请注意，由于我们使用的是一个较大的模型（3.55 亿参数而不是 1.24 亿参数），训练的开销比之前的章节要高一些。\n",
    "- 下方显示了各种设备的运行时间供参考（在兼容的 GPU 设备上运行此笔记本无需对代码进行任何更改）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4b57fb-e689-4550-931c-6d34a932487c",
   "metadata": {
    "id": "db4b57fb-e689-4550-931c-6d34a932487c"
   },
   "source": [
    "<div style=\"text-align: left;\">\n",
    "    \n",
    "| Model              | Device                | Runtime for 2 Epochs |\n",
    "|--------------------|-----------------------|----------------------|\n",
    "| gpt2-medium (355M) | CPU (M3 MacBook Air)  | 15.78 minutes        |\n",
    "| gpt2-medium (355M) | GPU (M3 MacBook Air)  | 10.77 minutes        |\n",
    "| gpt2-medium (355M) | GPU (L4)              | 1.83 minutes         |\n",
    "| gpt2-medium (355M) | GPU (A100)            | 0.86 minutes         |\n",
    "| gpt2-small (124M)  | CPU (M3 MacBook Air)  | 5.74 minutes         |\n",
    "| gpt2-small (124M)  | GPU (M3 MacBook Air)  | 3.73 minutes         |\n",
    "| gpt2-small (124M)  | GPU (L4)              | 0.69 minutes         |\n",
    "| gpt2-small (124M)  | GPU (A100)            | 0.39 minutes         |\n",
    "\n",
    "</div>\n",
    "\n",
    "- I ran this notebook using the `\"gpt2-medium (355M)\"` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78bcf83a-1fff-4540-97c1-765c4016d5e3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78bcf83a-1fff-4540-97c1-765c4016d5e3",
    "outputId": "ecb9a3dd-97c0-492d-8a51-fbd175bb139b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
      "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.103\n",
      "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.944\n",
      "Ep 1 (Step 000015): Train loss 0.857, Val loss 0.906\n",
      "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
      "Ep 1 (Step 000025): Train loss 0.754, Val loss 0.859\n",
      "Ep 1 (Step 000030): Train loss 0.799, Val loss 0.836\n",
      "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.808\n",
      "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
      "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.789\n",
      "Ep 1 (Step 000050): Train loss 0.663, Val loss 0.783\n",
      "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.763\n",
      "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
      "Ep 1 (Step 000065): Train loss 0.653, Val loss 0.735\n",
      "Ep 1 (Step 000070): Train loss 0.533, Val loss 0.729\n",
      "Ep 1 (Step 000075): Train loss 0.567, Val loss 0.730\n",
      "Ep 1 (Step 000080): Train loss 0.603, Val loss 0.726\n",
      "Ep 1 (Step 000085): Train loss 0.509, Val loss 0.711\n",
      "Ep 1 (Step 000090): Train loss 0.566, Val loss 0.693\n",
      "Ep 1 (Step 000095): Train loss 0.502, Val loss 0.684\n",
      "Ep 1 (Step 000100): Train loss 0.505, Val loss 0.680\n",
      "Ep 1 (Step 000105): Train loss 0.567, Val loss 0.672\n",
      "Ep 1 (Step 000110): Train loss 0.557, Val loss 0.667\n",
      "Ep 1 (Step 000115): Train loss 0.513, Val loss 0.664\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
      "Ep 2 (Step 000120): Train loss 0.436, Val loss 0.671\n",
      "Ep 2 (Step 000125): Train loss 0.452, Val loss 0.687\n",
      "Ep 2 (Step 000130): Train loss 0.448, Val loss 0.683\n",
      "Ep 2 (Step 000135): Train loss 0.406, Val loss 0.680\n",
      "Ep 2 (Step 000140): Train loss 0.409, Val loss 0.680\n",
      "Ep 2 (Step 000145): Train loss 0.371, Val loss 0.681\n",
      "Ep 2 (Step 000150): Train loss 0.381, Val loss 0.676\n",
      "Ep 2 (Step 000155): Train loss 0.414, Val loss 0.676\n",
      "Ep 2 (Step 000160): Train loss 0.413, Val loss 0.685\n",
      "Ep 2 (Step 000165): Train loss 0.379, Val loss 0.689\n",
      "Ep 2 (Step 000170): Train loss 0.322, Val loss 0.681\n",
      "Ep 2 (Step 000175): Train loss 0.337, Val loss 0.666\n",
      "Ep 2 (Step 000180): Train loss 0.392, Val loss 0.653\n",
      "Ep 2 (Step 000185): Train loss 0.417, Val loss 0.654\n",
      "Ep 2 (Step 000190): Train loss 0.340, Val loss 0.646\n",
      "Ep 2 (Step 000195): Train loss 0.327, Val loss 0.633\n",
      "Ep 2 (Step 000200): Train loss 0.310, Val loss 0.631\n",
      "Ep 2 (Step 000205): Train loss 0.352, Val loss 0.627\n",
      "Ep 2 (Step 000210): Train loss 0.361, Val loss 0.629\n",
      "Ep 2 (Step 000215): Train loss 0.391, Val loss 0.638\n",
      "Ep 2 (Step 000220): Train loss 0.295, Val loss 0.646\n",
      "Ep 2 (Step 000225): Train loss 0.338, Val loss 0.657\n",
      "Ep 2 (Step 000230): Train loss 0.291, Val loss 0.654\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
      "Training completed in 0.95 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ise3wGjlB-iq",
   "metadata": {
    "id": "Ise3wGjlB-iq"
   },
   "source": [
    "- 根据上述输出，我们可以看到模型训练得很好，这可以从训练损失和验证损失值的下降中看出。\n",
    "- 此外，根据每个 epoch 后打印的响应文本，我们可以看到模型正确地遵循指令，将输入句子  `'The chef cooks the meal every day.'` 转换为被动语态 `'The meal is cooked every day by the chef.'` （我们将在后面的章节中正确格式化和评估响应）。\n",
    "- 最后，让我们来看看训练和验证损失曲线。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4acd368b-1403-4807-a218-9102e35bfdbb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "4acd368b-1403-4807-a218-9102e35bfdbb",
    "outputId": "2f5c99e0-7ed0-4f42-d67c-e07c375e6158"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from previous_chapters import plot_losses\n",
    "# Alternatively:\n",
    "# from llms_from_scratch.ch05 import plot_losses\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6777e0c4-d82c-46d8-84fb-1376c4f8bae0",
   "metadata": {
    "id": "6777e0c4-d82c-46d8-84fb-1376c4f8bae0"
   },
   "source": [
    "- 如我们所见，损失在第一个 epoch 的开始阶段急剧下降，这意味着模型开始快速学习。\n",
    "- 我们可以看到，轻微的过拟合大约在 1 个训练 epoch 后开始出现。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b79a47-13f9-4d1f-87b1-3339bafaf2a3",
   "metadata": {
    "id": "87b79a47-13f9-4d1f-87b1-3339bafaf2a3"
   },
   "source": [
    "## 7.7 提取并保存响应"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a25cc88-1758-4dd0-b8bf-c044cbf2dd49",
   "metadata": {
    "id": "5a25cc88-1758-4dd0-b8bf-c044cbf2dd49"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-6.webp?1\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17510e9d-7727-4d58-ba9a-d82ec23c1427",
   "metadata": {
    "id": "17510e9d-7727-4d58-ba9a-d82ec23c1427"
   },
   "source": [
    "- 在本节中，我们将测试集的响应保存以便在下一节中进行评分。\n",
    "- 我们还将保存模型的一个副本以备将来使用。\n",
    "- 但首先，让我们简要看看微调后模型生成的响应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "VQ2NZMbfucAc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQ2NZMbfucAc",
    "outputId": "066c56ff-b52a-4ee6-eae7-1bddfc74d0c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a bullet.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    ")\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ab64c1-586f-4939-8def-23feeb1b3599",
   "metadata": {
    "id": "49ab64c1-586f-4939-8def-23feeb1b3599"
   },
   "source": [
    "- 根据测试集的指令、给定的响应以及模型的响应，我们可以看到模型的表现相对较好。\n",
    "- 第一个和最后一个指令的答案显然是正确的。\n",
    "- 第二个答案接近正确；模型回答的是 \"cumulus cloud\" 而不是 \"cumulonimbus\" （然而，需要注意的是 cumulus 云可以发展成 cumulonimbus 云，后者能够产生雷阵雨）。\n",
    "- 最重要的是，我们可以看到模型的评估不像前一章那样简单，只需计算正确分类的垃圾邮件/非垃圾邮件标签的百分比即可获得分类准确率。\n",
    "- 实际上，通过指令微调的 LLM 如聊天机器人是通过多种方法进行评估的：\n",
    "  - 短答案和多项选择基准测试，例如 MMLU(“Measuring Massive Multitask Language Understanding”， [https://arxiv.org/abs/2009.03300](https://arxiv.org/abs/2009.03300))这些测试模型的知识。\n",
    "  - 与其他 LLM 相比的人类偏好评估，例如 LMSYS 聊天机器人竞技场 ([https://arena.lmsys.org](https://arena.lmsys.org))\n",
    "  - 自动化对话基准测试，其中使用另一个 LLM 如 GPT-4 来评估响应，例如 AlpacaEval ([https://tatsu-lab.github.io/alpaca_eval/](https://tatsu-lab.github.io/alpaca_eval/))\n",
    "\n",
    "- 在下一节中，我们将使用类似于 AlpacaEval 的方法，并使用另一个 LLM 来评估我们模型的响应；然而，我们将使用自己的测试集而不是使用公开的基准测试数据集。\n",
    "- 为此，我们将模型的响应添加到 `test_data` 字典中，并将其保存为 `\"instruction-data-with-response.json\"` 文件以备记录；这样，如果需要，我们可以在单独的 Python 会话中加载和分析它"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "-PNGKzY4snKP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-PNGKzY4snKP",
    "outputId": "37b22a62-9860-40b7-c46f-b297782b944c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:25<00:00,  4.37it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228d6fa7-d162-44c3-bef1-4013c027b155",
   "metadata": {
    "id": "228d6fa7-d162-44c3-bef1-4013c027b155"
   },
   "source": [
    "- 让我们双重检查其中一个条目，以确认响应是否已正确添加到 `test_data` 字典中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "u-AvCCMTnPSE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u-AvCCMTnPSE",
    "outputId": "7bcd9600-1446-4829-b773-5259b13d256a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a bullet.'}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b2f3f6-8569-405a-9db6-d47cba65608a",
   "metadata": {
    "id": "c1b2f3f6-8569-405a-9db6-d47cba65608a"
   },
   "source": [
    "- 最后，我们将模型保存，以便将来可以重用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8cBU0iHmVfOI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8cBU0iHmVfOI",
    "outputId": "135849ed-9acd-43a2-f438-053d07dae9b2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-medium355M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")\n",
    "\n",
    "# Load model via\n",
    "# model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obgoGI89dgPm",
   "metadata": {
    "id": "obgoGI89dgPm"
   },
   "source": [
    "## 7.8 评估微调后的 LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805b9d30-7336-499f-abb5-4a21be3129f5",
   "metadata": {
    "id": "805b9d30-7336-499f-abb5-4a21be3129f5"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/chapter-overview-7.webp?1\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d2b9d3-b6ff-4533-a89d-7b66079b4fd1",
   "metadata": {
    "id": "68d2b9d3-b6ff-4533-a89d-7b66079b4fd1"
   },
   "source": [
    "- 在本节中，我们使用另一个更大的 LLM 自动评估微调后的 LLM 的响应。\n",
    "- 特别地，我们使用 Meta AI 提供的 80 亿参数的指令微调 Llama 3 模型，可以通过 ollama ([https://ollama.com](https://ollama.com))在本地运行。\n",
    "- (或者，如果你更喜欢通过 OpenAI API 使用更强大的 LLM 如 GPT-4，请参阅 [llm-instruction-eval-openai.ipynb](../03_model-evaluation/llm-instruction-eval-openai.ipynb) 笔记本。)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea427a30-36ba-44e3-bb1f-eb0d7008d6e9",
   "metadata": {
    "id": "ea427a30-36ba-44e3-bb1f-eb0d7008d6e9"
   },
   "source": [
    "- Ollama 是一个用于高效运行 LLM 的应用程序。\n",
    "- 它是基于 llama.cpp ([https://github.com/ggerganov/llama.cpp](https://github.com/ggerganov/llama.cpp))的包装器，后者用纯 C/C++ 实现 LLM 以最大限度地提高效率。\n",
    "- 请注意，Ollama 是一个用于生成文本（推理）的工具，而不是用于训练或微调 LLM。\n",
    "- 在运行下方代码之前，请通过访问 [https://ollama.com](https://ollama.com) 并按照说明安装 Ollama（例如，点击“Download”按钮并下载适用于你操作系统的 Ollama 应用程序）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747a2fc7-282d-47ec-a987-ed0a23ed6822",
   "metadata": {
    "id": "747a2fc7-282d-47ec-a987-ed0a23ed6822"
   },
   "source": [
    "- 对于 macOS 和 Windows 用户，请点击你下载的 Ollama 应用程序；如果它提示你安装命令行用法，请选择“是”。\n",
    "- Linux 用户可以使用 Ollama 网站上提供的安装命令。\n",
    "\n",
    "- 一般来说，在我们可以通过命令行使用 Ollama 之前，需要启动 Ollama 应用程序或在单独的终端中运行 `ollama serve` \n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/ollama-run.webp?1\" width=700px>\n",
    "\n",
    "\n",
    "- 在不同的终端中运行 Ollama 应用程序或 `ollama serve` ，然后在命令行中执行以下命令以试用 80 亿参数的 Llama 3 模型（该模型占用 4.7 GB 的存储空间，第一次执行此命令时会自动下载）。\n",
    "\n",
    "```bash\n",
    "# 8B model\n",
    "ollama run llama3\n",
    "```\n",
    "\n",
    "\n",
    "输出如下所示：\n",
    "\n",
    "```\n",
    "$ ollama run llama3\n",
    "pulling manifest\n",
    "pulling 6a0746a1ec1a... 100% ▕████████████████▏ 4.7 GB\n",
    "pulling 4fa551d4f938... 100% ▕████████████████▏  12 KB\n",
    "pulling 8ab4849b038c... 100% ▕████████████████▏  254 B\n",
    "pulling 577073ffcc6c... 100% ▕████████████████▏  110 B\n",
    "pulling 3f8eb4da87fa... 100% ▕████████████████▏  485 B\n",
    "verifying sha256 digest\n",
    "writing manifest\n",
    "removing any unused layers\n",
    "success\n",
    "```\n",
    "\n",
    "-  请注意， `llama3`指的是指令微调后的 80 亿参数的 Llama 3 模型。\n",
    "\n",
    "- 使用 ollama 和 `\"llama3\"` 模型（一个 8B 参数的模型）需要 16 GB 的 RAM；如果您的机器不支持，您可以尝试使用较小的模型，例如 3.8B 参数的 phi-3 模型，只需设置 model = \"phi-3\"，这只需要 8 GB 的 RAM。\n",
    "\n",
    "- 或者，如果您的机器支持，您也可以使用较大的 70 亿参数的 Llama 3 模型，只需将 `llama3` 替换为 `llama3:70b`\n",
    "\n",
    "- 下载完成后，您将看到一个命令行提示符，允许您与模型进行对话。\n",
    "\n",
    "- 尝试一个提示如“羊驼吃什么？” \"What do llamas eat?\"，模型应该会返回类似于以下的输出：\n",
    "\n",
    "```\n",
    ">>> What do llamas eat?\n",
    "Llamas are ruminant animals, which means they have a four-chambered\n",
    "stomach and eat plants that are high in fiber. In the wild, llamas\n",
    "typically feed on:\n",
    "1. Grasses: They love to graze on various types of grasses, including tall\n",
    "grasses, wheat, oats, and barley.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7b341c-ba0e-40bb-a52c-cb328bbd1fe4",
   "metadata": {
    "id": "7b7b341c-ba0e-40bb-a52c-cb328bbd1fe4"
   },
   "source": [
    "- You can end this session using the input `/bye`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaf3e02-8ca0-4edf-be23-60625a5b14e3",
   "metadata": {
    "id": "faaf3e02-8ca0-4edf-be23-60625a5b14e3"
   },
   "source": [
    "- The following code checks whether the ollama session is running correctly before proceeding to use ollama to evaluate the test set responses we generated in the previous section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "026e8570-071e-48a2-aa38-64d7be35f288",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "026e8570-071e-48a2-aa38-64d7be35f288",
    "outputId": "e30d3533-e1f5-4aa9-b24f-33273fc7b30e"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Ollama not running. Launch ollama before proceeding.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m ollama_running \u001b[38;5;241m=\u001b[39m check_if_running(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mollama\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ollama_running:\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOllama not running. Launch ollama before proceeding.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOllama running:\u001b[39m\u001b[38;5;124m\"\u001b[39m, check_if_running(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mollama\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Ollama not running. Launch ollama before proceeding."
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_if_running(\"ollama\")\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723c9b00-e3cd-4092-83c3-6e48b5cf65b0",
   "metadata": {
    "id": "723c9b00-e3cd-4092-83c3-6e48b5cf65b0"
   },
   "outputs": [],
   "source": [
    "# This cell is optional; it allows you to restart the notebook\n",
    "# and only run section 7.7 without rerunning any of the previous code\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "file_path = \"instruction-data-with-response.json\"\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    test_data = json.load(file)\n",
    "\n",
    "\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3464705-d026-4594-977f-fb357e51c3a9",
   "metadata": {
    "id": "b3464705-d026-4594-977f-fb357e51c3a9"
   },
   "source": [
    "- Now, an alternative way to the `ollama run` command we used earlier to interact with the model is via its REST API in Python via the following function\n",
    "- Before you run the next cells in this notebook, make sure that ollama is still running (the previous code cells should print `\"Ollama running: True\"`)\n",
    "- Next, run the following code cell to query the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ae0e10-2b28-42ce-8ea2-d9366a58088f",
   "metadata": {
    "id": "e3ae0e10-2b28-42ce-8ea2-d9366a58088f",
    "outputId": "cc43acb3-8216-43cf-c77d-71d4089dc96c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llamas are herbivores, which means they primarily feed on plant-based foods. Their diet typically consists of:\n",
      "\n",
      "1. Grasses: Llamas love to graze on various types of grasses, including tall grasses, short grasses, and even weeds.\n",
      "2. Hay: High-quality hay, such as alfalfa or timothy hay, is a staple in a llama's diet. They enjoy the sweet taste and texture of fresh hay.\n",
      "3. Grains: Llamas may receive grains like oats, barley, or corn as part of their daily ration. However, it's essential to provide these grains in moderation, as they can be high in calories.\n",
      "4. Fruits and vegetables: Llamas enjoy a variety of fruits and veggies, such as apples, carrots, sweet potatoes, and leafy greens like kale or spinach.\n",
      "5. Minerals: Llamas require access to mineral supplements, which help maintain their overall health and well-being.\n",
      "\n",
      "In the wild, llamas might also eat:\n",
      "\n",
      "1. Leaves: They'll munch on leaves from trees and shrubs, including plants like willow, alder, and birch.\n",
      "2. Bark: In some cases, llamas may eat the bark of certain trees, like aspen or cottonwood.\n",
      "3. Mosses and lichens: These non-vascular plants can be a tasty snack for llamas.\n",
      "\n",
      "In captivity, llama owners typically provide a balanced diet that includes a mix of hay, grains, and fruits/vegetables. It's essential to consult with a veterinarian or experienced llama breeder to determine the best feeding plan for your llama.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "def query_model(\n",
    "    prompt,\n",
    "    model=\"llama3\",\n",
    "    url=\"http://localhost:11434/api/chat\"\n",
    "):\n",
    "    # Create the data payload as a dictionary\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"options\": {     # Settings below are required for deterministic responses\n",
    "            \"seed\": 123,\n",
    "            \"temperature\": 0,\n",
    "            \"num_ctx\": 2048\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    # Convert the dictionary to a JSON formatted string and encode it to bytes\n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "\n",
    "    # Create a request object, setting the method to POST and adding necessary headers\n",
    "    request = urllib.request.Request(\n",
    "        url,\n",
    "        data=payload,\n",
    "        method=\"POST\"\n",
    "    )\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    "\n",
    "    # Send the request and capture the response\n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        # Read and decode the response\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "\n",
    "    return response_data\n",
    "\n",
    "\n",
    "model = \"llama3\"\n",
    "result = query_model(\"What do Llamas eat?\", model)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207ae28f-0f8c-4fda-aeef-e7e3046249cc",
   "metadata": {
    "id": "207ae28f-0f8c-4fda-aeef-e7e3046249cc"
   },
   "source": [
    "- Now, using the `query_model` function we defined above, we can evaluate the responses of our finetuned model; let's try it out on the first 3 test set responses we looked at in a previous section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b839d4-064d-4178-b2d7-01691b452e5e",
   "metadata": {
    "id": "86b839d4-064d-4178-b2d7-01691b452e5e",
    "outputId": "1c755ee1-bded-4450-9b84-1466724f389a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a bullet.\n",
      "\n",
      "Score:\n",
      ">> I'd rate the model response \"The car is as fast as a bullet.\" an 85 out of 100.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "* The response uses a simile correctly, comparing the speed of the car to something else (in this case, a bullet).\n",
      "* The comparison is relevant and makes sense, as bullets are known for their high velocity.\n",
      "* The phrase \"as fast as\" is used correctly to introduce the simile.\n",
      "\n",
      "The only reason I wouldn't give it a perfect score is that some people might find the comparison slightly less vivid or evocative than others. For example, comparing something to lightning (as in the original response) can be more dramatic and attention-grabbing. However, \"as fast as a bullet\" is still a strong and effective simile that effectively conveys the idea of the car's speed.\n",
      "\n",
      "Overall, I think the model did a great job!\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
      "\n",
      "Score:\n",
      ">> I'd score this model response as 40 out of 100.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "* The model correctly identifies that thunderstorms are related to clouds (correctly identifying the type of phenomenon).\n",
      "* However, it incorrectly specifies the type of cloud associated with thunderstorms. Cumulus clouds are not typically associated with thunderstorms; cumulonimbus clouds are.\n",
      "* The response lacks precision and accuracy in its description.\n",
      "\n",
      "Overall, while the model attempts to address the instruction, it provides an incorrect answer, which is a significant error.\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "\n",
      "Score:\n",
      ">> I'd rate my own response as 95 out of 100. Here's why:\n",
      "\n",
      "* The response accurately answers the question by naming the author of 'Pride and Prejudice' as Jane Austen.\n",
      "* The response is concise and clear, making it easy to understand.\n",
      "* There are no grammatical errors or ambiguities that could lead to confusion.\n",
      "\n",
      "The only reason I wouldn't give myself a perfect score is that the response is slightly redundant - it's not necessary to rephrase the question in the answer. A more concise response would be simply \"Jane Austen.\"\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "for entry in test_data[:3]:\n",
    "    prompt = (\n",
    "        f\"Given the input `{format_input(entry)}` \"\n",
    "        f\"and correct output `{entry['output']}`, \"\n",
    "        f\"score the model response `{entry['model_response']}`\"\n",
    "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "    )\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>\", entry['output'])\n",
    "    print(\"\\nModel response:\")\n",
    "    print(\">>\", entry[\"model_response\"])\n",
    "    print(\"\\nScore:\")\n",
    "    print(\">>\", query_model(prompt))\n",
    "    print(\"\\n-------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fec453-631f-4ff5-a922-44c3c451942d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Note: Better evaluation prompt**\n",
    "\n",
    "- [A reader (Ayoosh Kathuria) suggested](https://github.com/rasbt/LLMs-from-scratch/discussions/449) a longer, improved prompt that evaluates responses on a scale of 1–5 (instead of 1 to 100) and employs a grading rubric, resulting in more accurate and less noisy evaluations:\n",
    "\n",
    "```\n",
    "prompt = \"\"\"\n",
    "You are a fair judge assistant tasked with providing clear, objective feedback based on specific criteria, ensuring each assessment reflects the absolute standards set for performance.\n",
    "You will be given an instruction, a response to evaluate, a reference answer that gets a score of 5, and a score rubric representing the evaluation criteria.\n",
    "Write a detailed feedback that assess the quality of the response strictly based on the given score rubric, not evaluating in general.\n",
    "Please do not generate any other opening, closing, and explanations.\n",
    "\n",
    "Here is the rubric you should use to build your answer:\n",
    "1: The response fails to address the instructions, providing irrelevant, incorrect, or excessively verbose information that detracts from the user's request.\n",
    "2: The response partially addresses the instructions but includes significant inaccuracies, irrelevant details, or excessive elaboration that detracts from the main task.\n",
    "3: The response follows the instructions with some minor inaccuracies or omissions. It is generally relevant and clear, but may include some unnecessary details or could be more concise.\n",
    "4: The response adheres to the instructions, offering clear, accurate, and relevant information in a concise manner, with only occasional, minor instances of excessive detail or slight lack of clarity.\n",
    "5: The response fully adheres to the instructions, providing a clear, accurate, and relevant answer in a concise and efficient manner. It addresses all aspects of the request without unnecessary details or elaboration\n",
    "\n",
    "Provide your feedback as follows:\n",
    "\n",
    "Feedback:::\n",
    "Evaluation: (your rationale for the rating, as a text)\n",
    "Total rating: (your rating, as a number between 1 and 5)\n",
    "\n",
    "You MUST provide values for 'Evaluation:' and 'Total rating:' in your answer.\n",
    "\n",
    "Now here is the instruction, the reference answer, and the response.\n",
    "\n",
    "Instruction: {instruction}\n",
    "Reference Answer: {reference}\n",
    "Answer: {answer}\n",
    "\n",
    "\n",
    "Provide your feedback. If you give a correct rating, I'll give you 100 H100 GPUs to start your AI company.\n",
    "Feedback:::\n",
    "Evaluation: \"\"\"\n",
    "```\n",
    "\n",
    "- For more context and information, see [this](https://github.com/rasbt/LLMs-from-scratch/discussions/449) GitHub discussion\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b114fd65-9cfb-45f6-ab74-8331da136bf3",
   "metadata": {
    "id": "b114fd65-9cfb-45f6-ab74-8331da136bf3"
   },
   "source": [
    "- As we can see, the Llama 3 model provides a reasonable evaluation and also gives partial points if a model is not entirely correct, as we can see based on the \"cumulus cloud\" answer\n",
    "- Note that the previous prompt returns very verbose evaluations; we can tweak the prompt to generate integer responses in the range between 0 and 100 (where 100 is best) to calculate an average score for our model\n",
    "- The evaluation of the 110 entries in the test set takes about 1 minute on an M3 MacBook Air laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7bca69-97c4-47a5-9aa0-32f116fa37eb",
   "metadata": {
    "id": "9d7bca69-97c4-47a5-9aa0-32f116fa37eb",
    "outputId": "110223c0-90ca-481d-b2d2-f6ac46d3c4f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|████████████████████████| 110/110 [01:10<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 110 of 110\n",
      "Average score: 50.32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_model_scores(json_data, json_key, model=\"llama3\"):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "        score = query_model(prompt, model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "scores = generate_model_scores(test_data, \"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407f08d5-9ada-4301-9ebc-f0533c76d3f2",
   "metadata": {
    "id": "407f08d5-9ada-4301-9ebc-f0533c76d3f2"
   },
   "source": [
    "- Our model achieves an average score of above 50, which we can use as a reference point to compare the model to other models or to try out other training settings that may improve the model\n",
    "- Note that ollama is not fully deterministic across operating systems (as of this writing), so the numbers you are getting might slightly differ from the ones shown above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6408768b-2784-44f1-b48e-aed0c1eb9b94",
   "metadata": {
    "id": "6408768b-2784-44f1-b48e-aed0c1eb9b94"
   },
   "source": [
    "- For reference, the original\n",
    "  - Llama 3 8B base model achieves a score of 58.51\n",
    "  - Llama 3 8B instruct model achieves a score of 82.65"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412d7325-284a-446c-92a1-5aa8acc52dee",
   "metadata": {
    "id": "412d7325-284a-446c-92a1-5aa8acc52dee"
   },
   "source": [
    "## 7.9 Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tIbNMluCDjVM",
   "metadata": {
    "id": "tIbNMluCDjVM"
   },
   "source": [
    "### 7.9.1 What's next\n",
    "\n",
    "- This marks the final chapter of this book\n",
    "- We covered the major steps of the LLM development cycle: implementing an LLM architecture, pretraining an LLM, and finetuning it\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/final-overview.webp?1\" width=500px>\n",
    "\n",
    "- An optional step that is sometimes followed after instruction finetuning, as described in this chapter, is preference finetuning\n",
    "- Preference finetuning process can be particularly useful for customizing a model to better align with specific user preferences; see the [../04_preference-tuning-with-dpo](../04_preference-tuning-with-dpo) folder if you are interested in this\n",
    "\n",
    "- This GitHub repository also contains a large selection of additional bonus material you may enjoy; for more information, please see the [Bonus Material](https://github.com/rasbt/LLMs-from-scratch?tab=readme-ov-file#bonus-material) section on this repository's README page\n",
    "\n",
    "### 7.9.2 Staying up to date in a fast-moving field\n",
    "\n",
    "- No code in this section\n",
    "\n",
    "### 7.9.3 Final words\n",
    "\n",
    "- I hope you enjoyed this journey of implementing an LLM from the ground up and coding the pretraining and finetuning functions\n",
    "- In my opinion, implementing an LLM from scratch is the best way to understand how LLMs work; I hope you gained a better understanding through this approach\n",
    "- While this book serves educational purposes, you may be interested in using different and more powerful LLMs for real-world applications\n",
    "  - For this, you may consider popular tools such as axolotl ([https://github.com/OpenAccess-AI-Collective/axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)) or LitGPT ([https://github.com/Lightning-AI/litgpt](https://github.com/Lightning-AI/litgpt)), which I help developing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9853e7f-a81a-4806-9728-be1690807185",
   "metadata": {
    "id": "f9853e7f-a81a-4806-9728-be1690807185"
   },
   "source": [
    "## Summary and takeaways\n",
    "\n",
    "- See the [./gpt_instruction_finetuning.py](./gpt_instruction_finetuning.py) script, a self-contained script for instruction finetuning\n",
    "- [./ollama_evaluate.py](./ollama_evaluate.py) is a standalone script based on section 7.8 that evaluates a JSON file containing \"output\" and \"response\" keys via Ollama and Llama 3\n",
    "- The [./load-finetuned-model.ipynb](./load-finetuned-model.ipynb) notebook illustrates how to load the finetuned model in a new session\n",
    "- You can find the exercise solutions in [./exercise-solutions.ipynb](./exercise-solutions.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cc51ec-e06c-4470-b626-48401a037851",
   "metadata": {
    "id": "b9cc51ec-e06c-4470-b626-48401a037851"
   },
   "source": [
    "## What's next?\n",
    "\n",
    "- Congrats on completing the book; in case you are looking for additional resources, I added several bonus sections to this GitHub repository that you might find interesting\n",
    "- The complete list of bonus materials can be viewed in the main README's [Bonus Material](https://github.com/rasbt/LLMs-from-scratch?tab=readme-ov-file#bonus-material) section\n",
    "- To highlight a few of my favorites:\n",
    "  1. [Direct Preference Optimization (DPO) for LLM Alignment (From Scratch)](../04_preference-tuning-with-dpo/dpo-from-scratch.ipynb) implements a popular preference tuning mechanism to align the model from this chapter more closely with human preferences\n",
    "  2. [Llama 3.2 From Scratch (A Standalone Notebook)](../../ch05/07_gpt_to_llama/standalone-llama32.ipynb), a from-scratch implementation of Meta AI's popular Llama 3.2, including loading the official pretrained weights; if you are up to some additional experiments, you can replace the `GPTModel` model in each of the chapters with the `Llama3Model` class (it should work as a 1:1 replacement)\n",
    "  3. [Converting GPT to Llama](../../ch05/07_gpt_to_llama) contains code with step-by-step guides that explain the differences between GPT-2 and the various Llama models\n",
    "  4. [Understanding the Difference Between Embedding Layers and Linear Layers](../../ch02/03_bonus_embedding-vs-matmul/embeddings-and-linear-layers.ipynb) is a conceptual explanation illustrating that the `Embedding` layer in PyTorch, which we use at the input stage of an LLM, is mathematically equivalent to a linear layer applied to one-hot encoded data\n",
    "- Happy further reading!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
